{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d78215f-79f9-42a9-9fb2-bb828bd4db9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           Review\n",
      "0   The product arrived on time. Packaging was great, and the quality is amazing!\n",
      "1                                        THIS PRODUCT IS JUST AMAZING! I LOVE IT.\n",
      "2     I bought this phone for $799, and it has a 120Hz display. Totally worth it!\n",
      "3                         Wow!!! This product is awesome... but a bit expensive??\n",
      "4                                             The laptop works perfectly fine.   \n",
      "5    Check out the full product details here: https://example.com/product-details\n",
      "6         <div><h2>Great Purchase!</h2><p>I am happy with this product.</p></div>\n",
      "7                The battry life is excelent, but the chargin cable is too short.\n",
      "8                       I can't believe it's so good! Didn't expect such quality.\n",
      "9                   Love this product! ???? Fast delivery ??, amazing quality! ??\n",
      "10                       TBH, I wasnt expecting much, but OMG, this is awesome!!\n",
      "11                          This is the best product I have ever used in my life!\n",
      "12  The shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"Review.csv\"\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87025063-e9d8-4d97-a804-a7920dd8be3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5      check out the full product details here: https://example.com/product-details\n",
      "6           <div><h2>great purchase!</h2><p>i am happy with this product.</p></div>\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: lowercased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lowercase conversion\n",
    "def convert_to_lowercase(text):\n",
    " return text.lower()\n",
    "    \n",
    "df[\"lowercased\"] = df[\"Review\"].apply(convert_to_lowercase)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"lowercased\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f84156-dd05-49a6-a4f2-d6e1ffb9f0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5                                         check out the full product details here: \n",
      "6           <div><h2>great purchase!</h2><p>i am happy with this product.</p></div>\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: urls_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removal of URLs\n",
    "import re\n",
    "\n",
    "# remove any URLs that start with \"http\" or \"www\" from the text\n",
    "def remove_urls(text):\n",
    " return re.sub(r'http\\S+|www\\S+', '', text)\n",
    "df[\"urls_removed\"] = df[\"lowercased\"].apply(remove_urls)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"urls_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8d1446-55b9-4a11-bc06-6c51ae4eeade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5                                         check out the full product details here: \n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: html_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Removal of HTML tags\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# extracts only the text, removing all HTML tags\n",
    "def remove_html_tags(text):\n",
    " return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "df[\"html_removed\"] = df[\"urls_removed\"].apply(remove_html_tags)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"html_removed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99c764a-db4e-405f-b10e-23e3465ada8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Removal of emojis (if any)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01memoji\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# replace emoji with ''\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremove_emojis\u001b[39m(text):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "# Removal of emojis (if any)\n",
    "import emoji\n",
    "\n",
    "# replace emoji with ''\n",
    "def remove_emojis(text):\n",
    " return emoji.replace_emoji(text, replace='')\n",
    "df[\"emojis_removed\"] = df[\"html_removed\"].apply(remove_emojis)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"emojis_removed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e63116c-47d6-4edd-a26e-8bb8f7127663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[38;5;70m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f994794-c095-447e-bb46-e27e3db39676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5                                         check out the full product details here: \n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: emojis_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "df[\"emojis_removed\"] = df[\"html_removed\"].apply(remove_emojis)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"emojis_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ca0e85-cfae-4c7f-95d5-d788219f12f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 25 (3644287090.py, line 26)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mescaped_word = re.escape(word) # Ensure special characters are escaped\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'for' statement on line 25\n"
     ]
    }
   ],
   "source": [
    "# Replace internet slang/chat words\n",
    "# Dictionary of slang words and their replacements\n",
    "slang_dict = {\n",
    " \"tbh\": \"to be honest\",\n",
    " \"omg\": \"oh my god\",\n",
    " \"lol\": \"laugh out loud\",\n",
    " \"idk\": \"I don't know\",\n",
    " \"brb\": \"be right back\",\n",
    " \"btw\": \"by the way\",\n",
    " \"imo\": \"in my opinion\",\n",
    " \"smh\": \"shaking my head\",\n",
    " \"fyi\": \"for your information\",\n",
    " \"np\": \"no problem\",\n",
    " \"ikr\": \"I know right\",\n",
    " \"asap\": \"as soon as possible\",\n",
    " \"bff\": \"best friend forever\",\n",
    " \"gg\": \"good game\",\n",
    " \"hmu\": \"hit me up\",\n",
    " \"rofl\": \"rolling on the floor laughing\"\n",
    "}\n",
    "# Function to replace slang words\n",
    "def replace_slang(text):\n",
    " # Create a list of escaped slang words\n",
    " escaped_slang_words = [] # Empty list to store escaped slang words\n",
    " for word in slang_dict.keys():\n",
    " escaped_word = re.escape(word) # Ensure special characters are escaped\n",
    " escaped_slang_words.append(escaped_word) # Add to list\n",
    " # Join the words using '|'\n",
    " slang_pattern = r'\\b(' + '|'.join(escaped_slang_words) + r')\\b'\n",
    " # Define a replacement function\n",
    " def replace_match(match):\n",
    " slang_word = match.group(0) # Extract matched slang word\n",
    " return slang_dict[slang_word.lower()] # Replace with full form\n",
    " # Use regex to replace slang words with full forms\n",
    " replaced_text = re.sub(slang_pattern, replace_match, text, flags=re.IGNORECASE)\n",
    " return replaced_text\n",
    "# Apply the function to the column\n",
    "df[\"slangs_replaced\"] = df[\"emojis_removed\"].apply(replace_slang)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"slangs_replaced\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bde2b15-4075-46b2-ad49-8995a048f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5                                         check out the full product details here: \n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10          to be honest, i wasnt expecting much, but oh my god, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: slangs_replaced, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Replace internet slang/chat words\n",
    "# Dictionary of slang words and their replacements\n",
    "slang_dict = {\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bff\": \"best friend forever\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"rofl\": \"rolling on the floor laughing\"\n",
    "}\n",
    "\n",
    "# Function to replace slang words\n",
    "def replace_slang(text):\n",
    "    # Create a list of escaped slang words\n",
    "    escaped_slang_words = []  # Empty list to store escaped slang words\n",
    "    for word in slang_dict.keys():\n",
    "        escaped_word = re.escape(word)  # Ensure special characters are escaped\n",
    "        escaped_slang_words.append(escaped_word)  # Add to list\n",
    "\n",
    "    # Join the words using '|'\n",
    "    slang_pattern = r'\\b(' + '|'.join(escaped_slang_words) + r')\\b'\n",
    "\n",
    "    # Define a replacement function\n",
    "    def replace_match(match):\n",
    "        slang_word = match.group(0)        # Extract matched slang word\n",
    "        return slang_dict[slang_word.lower()]  # Replace with full form\n",
    "\n",
    "    # Use regex to replace slang words with full forms\n",
    "    replaced_text = re.sub(slang_pattern, replace_match, text, flags=re.IGNORECASE)\n",
    "    return replaced_text\n",
    "\n",
    "# Apply the function to the column\n",
    "df[\"slangs_replaced\"] = df[\"emojis_removed\"].apply(replace_slang)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None for unlimited width\n",
    "print(df[\"slangs_replaced\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2403bd-414e-4c53-8309-c3e8a68e2862",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (3461171970.py, line 53)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mapostrophes)\u001b[39m\n               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "# Replace Contractions\n",
    "contractions_dict = {\n",
    " \"wasn't\": \"was not\",\n",
    " \"isn't\": \"is not\",\n",
    " \"aren't\": \"are not\",\n",
    " \"weren't\": \"were not\",\n",
    " \"doesn't\": \"does not\",\n",
    " \"don't\": \"do not\",\n",
    " \"didn't\": \"did not\",\n",
    " \"can't\": \"cannot\",\n",
    " \"couldn't\": \"could not\",\n",
    " \"shouldn't\": \"should not\",\n",
    " \"wouldn't\": \"would not\",\n",
    " \"won't\": \"will not\",\n",
    " \"haven't\": \"have not\",\n",
    " \"hasn't\": \"has not\",\n",
    " \"hadn't\": \"had not\",\n",
    " \"i'm\": \"i am\",\n",
    " \"you're\": \"you are\",\n",
    " \"he's\": \"he is\",\n",
    " \"she's\": \"she is\",\n",
    " \"it's\": \"it is\",\n",
    " \"we're\": \"we are\",\n",
    " \"they're\": \"they are\",\n",
    " \"i've\": \"i have\",\n",
    " \"you've\": \"you have\",\n",
    " \"we've\": \"we have\",\n",
    " \"they've\": \"they have\",\n",
    " \"i'd\": \"i would\",\n",
    " \"you'd\": \"you would\",\n",
    " \"he'd\": \"he would\",\n",
    " \"she'd\": \"she would\",\n",
    " \"we'd\": \"we would\",\n",
    " \"they'd\": \"they would\",\n",
    " \"i'll\": \"i will\",\n",
    " \"you'll\": \"you will\",\n",
    " \"he'll\": \"he will\",\n",
    " \"she'll\": \"she will\",\n",
    " \"we'll\": \"we will\",\n",
    " \"they'll\": \"they will\",\n",
    " \"let's\": \"let us\",\n",
    " \"that's\": \"that is\",\n",
    " \"who's\": \"who is\",\n",
    " \"what's\": \"what is\",\n",
    " \"where's\": \"where is\",\n",
    " \"when's\": \"when is\",\n",
    " \"why's\": \"why is\"\n",
    "}\n",
    "# Build the regex pattern for contractions\n",
    "escaped_contractions = [] # List to store escaped contractions\n",
    "for contraction in contractions_dict.keys():\n",
    " escaped_contraction = re.escape(contraction) # Escape special characters (e.g.,\n",
    "apostrophes)\n",
    " escaped_contractions.append(escaped_contraction) # Add to list\n",
    "# Join the escaped contractions with '|'\n",
    "joined_contractions = \"|\".join(escaped_contractions)\n",
    "# Create a regex pattern with word boundaries (\\b)\n",
    "contractions_pattern = r'\\b(' + joined_contractions + r')\\b'\n",
    "# Compile the regex\n",
    "compiled_pattern = re.compile(contractions_pattern, flags=re.IGNORECASE)\n",
    "# Define a function to replace contractions\n",
    "def replace_contractions(text):\n",
    " # Function to handle each match found\n",
    " def replace_match(match):\n",
    " matched_word = match.group(0) # Extract matched contraction\n",
    " lower_matched_word = matched_word.lower() # Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53be8dde-051d-40d6-9a94-57ac20aa5b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5                                         check out the full product details here: \n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                      i cannot believe it is so good! did not expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10          to be honest, i wasnt expecting much, but oh my god, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: contractions_replaced, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Replace Contractions\n",
    "contractions_dict = {\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"why's\": \"why is\"\n",
    "}\n",
    "\n",
    "# Build the regex pattern for contractions\n",
    "escaped_contractions = []  # List to store escaped contractions\n",
    "for contraction in contractions_dict.keys():\n",
    "    escaped_contraction = re.escape(contraction)  # Escape special characters (e.g., apostrophes)\n",
    "    escaped_contractions.append(escaped_contraction)  # Add to list\n",
    "\n",
    "# Join the escaped contractions with '|'\n",
    "joined_contractions = \"|\".join(escaped_contractions)\n",
    "\n",
    "# Create a regex pattern with word boundaries (\\b)\n",
    "contractions_pattern = r'\\b(' + joined_contractions + r')\\b'\n",
    "\n",
    "# Compile the regex\n",
    "compiled_pattern = re.compile(contractions_pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# Define a function to replace contractions\n",
    "def replace_contractions(text):\n",
    "    # Function to handle each match found\n",
    "    def replace_match(match):\n",
    "        matched_word = match.group(0)                          # Extract matched contraction\n",
    "        lower_matched_word = matched_word.lower()              # Convert to lowercase\n",
    "        expanded_form = contractions_dict[lower_matched_word]  # Get full form from dictionary\n",
    "        return expanded_form                                    # Return the expanded form\n",
    "\n",
    "    # Apply regex substitution\n",
    "    expanded_text = compiled_pattern.sub(replace_match, text)\n",
    "    return expanded_text  # Return modified text\n",
    "\n",
    "# Apply the function to a DataFrame column\n",
    "df[\"contractions_replaced\"] = df[\"slangs_replaced\"].apply(replace_contractions)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None for unlimited width\n",
    "print(df[\"contractions_replaced\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9168d384-8e53-4291-ba9a-651e33a35518",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'punctuations_removed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/anaconda-2025.12-py312/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'punctuations_removed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m  \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, text) \u001b[38;5;66;03m# Removes all numeric characters\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Apply the function to the column\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mnumbers_removed\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpunctuations_removed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.apply(remove_numbers)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Display column content without truncation\u001b[39;00m\n\u001b[32m      9\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_colwidth\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# Set to None for unlimited width\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/anaconda-2025.12-py312/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/anaconda-2025.12-py312/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'punctuations_removed'"
     ]
    }
   ],
   "source": [
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    " return re.sub(r'\\d+', '', text) # Removes all numeric characters\n",
    "    \n",
    "# Apply the function to the column\n",
    "df[\"numbers_removed\"] = df[\"punctuations_removed\"].apply(remove_numbers)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"numbers_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13c81fa3-c2cf-4b1e-9c3f-34fdcf011d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Review', 'lowercased', 'urls_removed', 'html_removed',\n",
      "       'emojis_removed', 'slangs_replaced', 'contractions_replaced'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "171c2228-d8ca-4bee-91b1-52f9c302708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2             i bought this phone for $, and it has a hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5                                         check out the full product details here: \n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                      i cannot believe it is so good! did not expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10          to be honest, i wasnt expecting much, but oh my god, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: numbers_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)  # Removes all numeric characters\n",
    "\n",
    "# Apply the function to the column\n",
    "df[\"numbers_removed\"] = df[\"contractions_replaced\"].apply(remove_numbers)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None for unlimited width\n",
    "print(df[\"numbers_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95277f39-6045-4318-a2fe-c0f03fb2e81e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'punctuations_removed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/anaconda-2025.12-py312/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'punctuations_removed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m  \u001b[38;5;28;01mreturn\u001b[39;00m re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, text) \u001b[38;5;66;03m# Removes all numeric characters\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Apply the function to the column\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mnumbers_removed\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpunctuations_removed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.apply(remove_numbers)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Display column content without truncation\u001b[39;00m\n\u001b[32m      7\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_colwidth\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# Set to None for unlimited width\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/anaconda-2025.12-py312/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/anaconda-2025.12-py312/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'punctuations_removed'"
     ]
    }
   ],
   "source": [
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    " return re.sub(r'\\d+', '', text) # Removes all numeric characters\n",
    "# Apply the function to the column\n",
    "df[\"numbers_removed\"] = df[\"punctuations_removed\"].apply(remove_numbers)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"numbers_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5429ed5-b940-46ad-a806-611344370e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time packaging was great and the quality is amazing\n",
      "1                                         this product is just amazing i love it\n",
      "2        i bought this phone for 799 and it has a 120hz display totally worth it\n",
      "3                                wow this product is awesome but a bit expensive\n",
      "4                                             the laptop works perfectly fine   \n",
      "5                                       check out the full product details here \n",
      "6                                     great purchasei am happy with this product\n",
      "7                 the battry life is excelent but the chargin cable is too short\n",
      "8                     i cannot believe it is so good did not expect such quality\n",
      "9                             love this product  fast delivery  amazing quality \n",
      "10            to be honest i wasnt expecting much but oh my god this is awesome\n",
      "11                          this is the best product i have ever used in my life\n",
      "12    the shoes were comfortable fitting nicely and worked perfectly for jogging\n",
      "Name: punctuations_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuations and special characters\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df[\"punctuations_removed\"] = df[\"contractions_replaced\"].apply(remove_punctuation)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"punctuations_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f9c541c-980d-4555-8047-d1d7ebf57f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time packaging was great and the quality is amazing\n",
      "1                                         this product is just amazing i love it\n",
      "2              i bought this phone for  and it has a hz display totally worth it\n",
      "3                                wow this product is awesome but a bit expensive\n",
      "4                                             the laptop works perfectly fine   \n",
      "5                                       check out the full product details here \n",
      "6                                     great purchasei am happy with this product\n",
      "7                 the battry life is excelent but the chargin cable is too short\n",
      "8                     i cannot believe it is so good did not expect such quality\n",
      "9                             love this product  fast delivery  amazing quality \n",
      "10            to be honest i wasnt expecting much but oh my god this is awesome\n",
      "11                          this is the best product i have ever used in my life\n",
      "12    the shoes were comfortable fitting nicely and worked perfectly for jogging\n",
      "Name: numbers_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)  # Removes all numeric characters\n",
    "\n",
    "df[\"numbers_removed\"] = df[\"punctuations_removed\"].apply(remove_numbers)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"numbers_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10519d31-31b7-42eb-af32-778ad3452d49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autocorrect'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Correct spelling mistakes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautocorrect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Speller\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialize spell checker\u001b[39;00m\n\u001b[32m      5\u001b[39m spell = Speller(lang=\u001b[33m'\u001b[39m\u001b[33men\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'autocorrect'"
     ]
    }
   ],
   "source": [
    "# Correct spelling mistakes\n",
    "from autocorrect import Speller\n",
    "\n",
    "# Initialize spell checker\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "# Function to correct spelling\n",
    "def correct_spelling(text):\n",
    " return spell(text) # Apply correction\n",
    "# Apply the function to the column\n",
    "df[\"spelling_corrected\"] = df[\"numbers_removed\"].apply(correct_spelling)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"spelling_corrected\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61bb0dbc-67f3-4cbd-88f8-27b30a2ff9ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autocorrect'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Correct spelling mistakes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautocorrect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Speller\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialize spell checker\u001b[39;00m\n\u001b[32m      5\u001b[39m spell = Speller(lang=\u001b[33m'\u001b[39m\u001b[33men\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'autocorrect'"
     ]
    }
   ],
   "source": [
    "# Correct spelling mistakes\n",
    "from autocorrect import Speller\n",
    "\n",
    "# Initialize spell checker\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "# Function to correct spelling\n",
    "def correct_spelling(text):\n",
    "    return spell(text)  # Apply correction\n",
    "\n",
    "# Apply the function to the column\n",
    "df[\"spelling_corrected\"] = df[\"numbers_removed\"].apply(correct_spelling)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None for unlimited width\n",
    "print(df[\"spelling_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f44d2d5-6319-420a-8d10-65363299d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
      "\u001b[2K     \u001b[38;5;70m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622414 sha256=328258ce7e083d854db00970329ea127dfdb990108fd260db8cc5a66cf5a2f47\n",
      "  Stored in directory: /home/9bd7767f-e2b1-4f3e-a47c-80a0c1669bd6/.cache/pip/wheels/b6/28/c2/9ddf8f57f871b55b6fd0ab99c887531fb9a66e5ff236b82aee\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a98df104-2dd9-4656-a4e2-960f82d578b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time packaging was great and the quality is amazing\n",
      "1                                         this product is just amazing i love it\n",
      "2              i bought this phone for  and it has a hz display totally worth it\n",
      "3                                wow this product is awesome but a bit expensive\n",
      "4                                             the laptop works perfectly fine   \n",
      "5                                       check out the full product details here \n",
      "6                                     great purchased am happy with this product\n",
      "7              the battery life is excellent but the charging cable is too short\n",
      "8                     i cannot believe it is so good did not expect such quality\n",
      "9                             love this product  fast delivery  amazing quality \n",
      "10            to be honest i wasnt expecting much but oh my god this is awesome\n",
      "11                          this is the best product i have ever used in my life\n",
      "12    the shoes were comfortable fitting nicely and worked perfectly for jogging\n",
      "Name: spelling_corrected, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Correct spelling mistakes\n",
    "from autocorrect import Speller\n",
    "\n",
    "# Initialize spell checker\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "# Function to correct spelling\n",
    "def correct_spelling(text):\n",
    "    return spell(text)  # Apply correction\n",
    "\n",
    "# Apply the function to the column\n",
    "df[\"spelling_corrected\"] = df[\"numbers_removed\"].apply(correct_spelling)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None for unlimited width\n",
    "print(df[\"spelling_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20057f4d-6b56-4d80-bd31-01155d38c62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/9bd7767f-e2b1-4f3e-a47c-\n",
      "[nltk_data]     80a0c1669bd6/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          product arrived time packaging great quality amazing\n",
      "1                                          product amazing love\n",
      "2                         bought phone hz display totally worth\n",
      "3                             wow product awesome bit expensive\n",
      "4                                   laptop works perfectly fine\n",
      "5                                    check full product details\n",
      "6                                 great purchased happy product\n",
      "7                   battery life excellent charging cable short\n",
      "8                            cannot believe good expect quality\n",
      "9                    love product fast delivery amazing quality\n",
      "10                  honest wasnt expecting much oh god awesome\n",
      "11                                  best product ever used life\n",
      "12    shoes comfortable fitting nicely worked perfectly jogging\n",
      "Name: stopwords_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stopwords list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()  # Split text into words\n",
    "    filtered_words = []   # Create an empty list to store words after stopword removal\n",
    "    for word in words:    # Loop through each word in the list of words\n",
    "        lower_word = word.lower()  # Convert the word to lowercase for uniform comparison\n",
    "        if lower_word not in stop_words:  # Check if the lowercase word is NOT in the stopwords list\n",
    "            filtered_words.append(word)   # If it's not a stopword, add it to the filtered list\n",
    "    return \" \".join(filtered_words)  # Join words back into a sentence\n",
    "\n",
    "# Apply the function to the column\n",
    "df[\"stopwords_removed\"] = df[\"spelling_corrected\"].apply(remove_stopwords)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None for unlimited width\n",
    "print(df[\"stopwords_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebe01f4f-1632-4765-8921-6828976d3fa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 7 (260970240.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn \"\"\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'if' statement on line 7\n"
     ]
    }
   ],
   "source": [
    "# Stemming - reduces words to their base root by chopping off suffixes\n",
    "from nltk.stem import PorterStemmer\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "# Function to apply stemming\n",
    "def stem_text(text):\n",
    " if not isinstance(text, str):\n",
    " return \"\"\n",
    "    \n",
    "words = text.split()\n",
    " stemmed_words = [stemmer.stem(word) for word in words] # Apply stemming\n",
    " return \" \".join(stemmed_words)\n",
    "# Apply the function\n",
    "df[\"stemmed_words\"] = df[\"stopwords_removed\"].apply(stem_text)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"stemmed_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1fdd2d2-d1ac-424f-a68f-df9e4bf21fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     product arriv time packag great qualiti amaz\n",
      "1                                product amaz love\n",
      "2              bought phone hz display total worth\n",
      "3                    wow product awesom bit expens\n",
      "4                       laptop work perfectli fine\n",
      "5                        check full product detail\n",
      "6                      great purchas happi product\n",
      "7              batteri life excel charg cabl short\n",
      "8                cannot believ good expect qualiti\n",
      "9          love product fast deliveri amaz qualiti\n",
      "10         honest wasnt expect much oh god awesom\n",
      "11                      best product ever use life\n",
      "12        shoe comfort fit nice work perfectli jog\n",
      "Name: stemmed_words, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Stemming - reduces words to their base root by chopping off suffixes\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to apply stemming\n",
    "def stem_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]  # Apply stemming\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "# Apply the function\n",
    "df[\"stemmed_words\"] = df[\"stopwords_removed\"].apply(stem_text)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None for unlimited width\n",
    "print(df[\"stemmed_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da4a1b9a-f27f-43f2-8422-bba43306fba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 16 (3511541710.py, line 17)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn wordnet.ADJ\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'if' statement on line 16\n"
     ]
    }
   ],
   "source": [
    "# Download the required resources\n",
    "nltk.download('wordnet') # For lemmatization\n",
    "nltk.download('omw-1.4') # WordNet lexical database\n",
    "nltk.download('averaged_perceptron_tagger_eng') # For POS tagging\n",
    "nltk.download('punkt_tab') # For tokenization\n",
    "# Lemmatization - reduces words to their base dictionary form (lemma)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Function to map NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(nltk_tag):\n",
    " if nltk_tag.startswith('J'): # Adjective\n",
    " return wordnet.ADJ\n",
    " elif nltk_tag.startswith('V'): # Verb\n",
    " return wordnet.VERB\n",
    " elif nltk_tag.startswith('N'): # Noun\n",
    " return wordnet.NOUN\n",
    " elif nltk_tag.startswith('R'): # Adverb\n",
    " return wordnet.ADV\n",
    " else:\n",
    " return wordnet.NOUN # Default to noun\n",
    "# Function to lemmatize text with POS tagging\n",
    "def lemmatize_text(text):\n",
    " if not isinstance(text, str): # Ensure input is a string\n",
    " return \"\"\n",
    " words = word_tokenize(text) # Tokenize text into words\n",
    " pos_tags = pos_tag(words) # Get POS tags\n",
    "\n",
    " # Lemmatize each word with its correct POS tag\n",
    " lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word,\n",
    "tag in pos_tags]\n",
    "\n",
    " return \" \".join(lemmatized_words) # Join words back into a sentence\n",
    "# Apply the function to the column\n",
    "df[\"lemmatized\"] = df[\"stopwords_removed\"].apply(lemmatize_text)\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None) # Set to None for unlimited width\n",
    "print(df[\"lemmatized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0be9f13-0325-4258-83f5-52cd9b3ee509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/9bd7767f-e2b1-4f3e-a47c-\n",
      "[nltk_data]     80a0c1669bd6/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/9bd7767f-e2b1-4f3e-a47c-\n",
      "[nltk_data]     80a0c1669bd6/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/9bd7767f-e2b1-4f3e-a47c-\n",
      "[nltk_data]     80a0c1669bd6/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/9bd7767f-e2b1-4f3e-a47c-\n",
      "[nltk_data]     80a0c1669bd6/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     product arrive time packaging great quality amazing\n",
      "1                                      product amaze love\n",
      "2                      buy phone hz display totally worth\n",
      "3                       wow product awesome bit expensive\n",
      "4                              laptop work perfectly fine\n",
      "5                               check full product detail\n",
      "6                            great purchase happy product\n",
      "7               battery life excellent charge cable short\n",
      "8                     can not believe good expect quality\n",
      "9              love product fast delivery amazing quality\n",
      "10               honest wasnt expect much oh god awesome\n",
      "11                             best product ever use life\n",
      "12         shoe comfortable fit nicely work perfectly jog\n",
      "Name: lemmatized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Download the required resources\n",
    "nltk.download('wordnet')                    # For lemmatization\n",
    "nltk.download('omw-1.4')                    # WordNet lexical database\n",
    "nltk.download('averaged_perceptron_tagger_eng')  # For POS tagging\n",
    "nltk.download('punkt_tab')                  # For tokenization\n",
    "\n",
    "# Lemmatization - reduces words to their base dictionary form (lemma)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to map NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):    # Adjective\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):  # Verb\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):  # Noun\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):  # Adverb\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN         # Default to noun\n",
    "\n",
    "# Function to lemmatize text with POS tagging\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):  # Ensure input is a string\n",
    "        return \"\"\n",
    "    words = word_tokenize(text)    # Tokenize text into words\n",
    "    pos_tags = pos_tag(words)      # Get POS tags\n",
    "\n",
    "    # Lemmatize each word with its correct POS tag\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "\n",
    "    return \" \".join(lemmatized_words)  # Join words back into a sentence\n",
    "\n",
    "# Apply the function to the column\n",
    "df[\"lemmatized\"] = df[\"stopwords_removed\"].apply(lemmatize_text)\n",
    "\n",
    "# Display column content without truncation\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None for unlimited width\n",
    "print(df[\"lemmatized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9bc4499-234e-4ef7-8bbf-18878e070e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Processed_Reviews.csv\", index=False) # Saves without the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dafe80-5ea7-425b-9dfd-d587ed1b248e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.12-py312",
   "language": "python",
   "name": "conda-env-anaconda-2025.12-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
